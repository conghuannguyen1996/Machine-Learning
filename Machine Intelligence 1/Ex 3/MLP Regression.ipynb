{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.5503' '-0.5894']\n",
      " ['0.9206' '-0.2507']\n",
      " ['0.5359' '-0.0468']\n",
      " ['0.6081' '-0.3402']\n",
      " ['0.0202' '0.2857']\n",
      " ['0.8545' '-1.0683']\n",
      " ['0.2357' '0.8605']\n",
      " ['0.4847' '-0.0801']\n",
      " ['0.3996' '0.6837']\n",
      " ['0.1957' '1.1850']]\n",
      "[0.5503, 0.9206, 0.5359, 0.6081, 0.0202, 0.8545, 0.2357, 0.4847, 0.3996, 0.1957]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "with open('RegressionData.txt') as f:\n",
    "    data=[i.split() for i in f]\n",
    "data = np.array(data)\n",
    "print(data)\n",
    "x_data = data[:,0]\n",
    "x_data = [float(i) for i in x_data]\n",
    "y_true = data[:,1]\n",
    "y_true = [float(i) for i in y_true]\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlpmodel:\n",
    "    def __init__(self):\n",
    "        self.number_hidden_layer = 1\n",
    "        self.bias = np.array([np.random.rand(3)-0.5, np.random.rand(1)-0.5])\n",
    "        self.w = np.random.rand(2,3)-0.5\n",
    "        print(\"weights = \" +str(self.w))\n",
    "        print(\"bias = \" +str(self.bias))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x * self.w[0]+self.bias[0]\n",
    "        x = np.tanh(x)\n",
    "        x = x @ self.w[1] + self.bias[1]\n",
    "        x = x\n",
    "        return x\n",
    "    \n",
    "    def error(self,y_pred, y_true):\n",
    "        return (y_pred-y_true)**2\n",
    "    \n",
    "    def train(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = [[-0.0796322  -0.16966518 -0.29535137]\n",
      " [ 0.11927097 -0.20034533 -0.23317272]]\n",
      "bias = [array([-0.0640051 , -0.47407377,  0.04966248]) array([-0.06467761])]\n",
      "[0.45607178]\n"
     ]
    }
   ],
   "source": [
    "model = Mlpmodel()\n",
    "np.random.seed(2)\n",
    "error = 0\n",
    "for (x,y) in zip(x_data,y_true):\n",
    "    y_pred = model.forward(x)\n",
    "    error += model.error(y_pred, y)\n",
    "error = error / len(x_data)    \n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
